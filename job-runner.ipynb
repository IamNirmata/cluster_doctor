{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6480392e",
   "metadata": {},
   "source": [
    "home directory: c-val\n",
    "function availability : ./kubectl/functions.py\n",
    "\n",
    "Now the job-runner.ipynb will perform the following tasks:\n",
    "1. get_free_node_list()\n",
    "    - save it to list - get_free_node_list[]\n",
    "2. get_db_latest_status() \n",
    "    - Get latest test results timmestamp from validation.db for all the nodes in the db ( by accessing gcr-admin-pvc-access pod)\n",
    "    - per node per test - latest timestamp\n",
    "    - if a node has no test results - mark it with very old timestamp - highest priority\n",
    "3. build_priority_queue()\n",
    "    - Combine free nodes list with get_db_latest_status list, and create a priority queue function that takes \n",
    "        1. free nodes list\n",
    "        2. db latest status\n",
    "        3. Z days threshold\n",
    "    - Returns priority queue\n",
    "        1. Filered free nodes only\n",
    "        2. skip nodes with test results not older than Z days \n",
    "        3. order by latest test results timestamps (oldest first - highest priority) \n",
    "    - Format of returned \"job_priority_queue_list\": [ nodename, priority_order, job_submission_status ]\n",
    "        [\n",
    "            [node1, 1, True],\n",
    "            [node2, 2, False],\n",
    "            ...\n",
    "        ]\n",
    "4. batch job submission\n",
    "   - takes \n",
    "        1. batch size: N single node jobs per batch\n",
    "        2. job queue list from build_priority_queue()\n",
    "        3. job template yaml file path  ( /home/hari/b200/validation/c-val/ymls/specific-node-job.yml )\n",
    "    - for each batch of N nodes\n",
    "        1. read job template yaml file\n",
    "        2. edit/ fill in \n",
    "            a. node name <node-name>\n",
    "            b. job name hari-gcr-ceval-<node-name>-<timestamp>\n",
    "        3. submit job to k8s cluster and repeat N times ( for batch size )\n",
    "5. monitor job status\n",
    "    - if a job pending for more than X minutes - cancel the job and update job_submission_status to canceled in job_priority_queue_list\n",
    "For each node in job queue list\n",
    "    - Create a job to run cluster-doctor validation tests on that node\n",
    "\n",
    "6. Job run[Inside Job pod] \n",
    "    - git clone c-val repo to /opt/c-val\n",
    "    - Run cluster-doctor tests on the pod/node and collect logs ( STDOUT/ STDERR) using tee\n",
    "    - Upon completion of tests\n",
    "        -Collect test results log ( STDOUT/ STDERR) and save it to /data/continuous_validation/<test-name>/<node-name>/<node-name>-<testname>-<timestamp>.log\n",
    "    - Update validation.db with new test results and timestamp at /data/continuous_validation/metadata/validation.db using /opt/c-val/kubectl/functions.py/add_result_local()\n",
    "\n",
    "7. Generate a daily report\n",
    "    - Summary of nodes tested\n",
    "    - Summary of test results\n",
    "    - List of nodes that were never tested\n",
    "    - Save report to ./gitignored/reports/daily_report_<date>.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7935a907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import importlib\n",
    "\n",
    "# Add the current directory to path to ensure we can import utils\n",
    "current_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "if current_dir not in sys.path:\n",
    "    sys.path.append(current_dir)\n",
    "\n",
    "# Import the utility functions\n",
    "try:\n",
    "    import utils.functions as functions\n",
    "    importlib.reload(functions) # Force reload to get new functions\n",
    "except ImportError:\n",
    "    # Fallback if running from a different context\n",
    "    sys.path.append(\"/home/hari/b200/validation/c-val\")\n",
    "    import utils.functions as functions\n",
    "    importlib.reload(functions)\n",
    "\n",
    "home_dir = \"/home/hari/b200/validation/c-val/\"\n",
    "batch_size = 2\n",
    "monitor_timeout_mins = 2\n",
    "template_path = os.path.join(home_dir, \"ymls/specific-node-job.yml\")\n",
    "days_threshold = 7\n",
    "\n",
    "class Cluster:\n",
    "    def __init__(self, ns=\"gcr-admin\"):\n",
    "        self.ns = ns\n",
    "        # numerical timestamp\n",
    "        self.timestamp = int(time.time())\n",
    "        self.freenode_list = []\n",
    "        self.db_status = {}\n",
    "        self.job_queue = []\n",
    "        self.template_path = template_path\n",
    "        self.home_dir = home_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.monitor_timeout_mins = monitor_timeout_mins\n",
    "        self.days_threshold = days_threshold\n",
    "        \n",
    "    def refresh_state(self):\n",
    "        \"\"\"\n",
    "        Step 1 & 2: Get free nodes and latest DB status.\n",
    "        \"\"\"\n",
    "        print(f\"[{datetime.datetime.now().time()}] Refreshing cluster state...\")\n",
    "        \n",
    "        # 1. Get Free Node List\n",
    "        self.freenode_list = functions.get_free_node_list()\n",
    "        print(f\"  Found {len(self.freenode_list)} free nodes (fully avaialble).\")\n",
    "        \n",
    "        # 2. Get DB Latest Status\n",
    "        print(\"  Fetching DB status from cluster...\")\n",
    "        try:\n",
    "            db_output = functions.get_db_latest_status(namespace=self.ns)\n",
    "            self.db_status = functions.parse_db_status_output(db_output)\n",
    "            print(f\"  Retrieved status for {len(self.db_status)} nodes from DB.\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error fetching DB status: {e}\")\n",
    "            self.db_status = {}\n",
    "            \n",
    "    def build_priority_queue(self, days_threshold=None, shuffle=False):\n",
    "        \"\"\"\n",
    "        Step 3: Build a priority queue filtering free nodes by age of last test.\n",
    "        \"\"\"\n",
    "        if not self.freenode_list:\n",
    "            print(\"No free nodes to queue.\")\n",
    "            self.job_queue = []\n",
    "            return []\n",
    "\n",
    "        print(f\"[{datetime.datetime.now().time()}] Building priority queue (Threshold: {days_threshold} days, Shuffle: {shuffle})...\")\n",
    "        self.job_queue = functions.build_priority_queue(\n",
    "            self.freenode_list, \n",
    "            self.db_status, \n",
    "            days_threshold=days_threshold,\n",
    "            shuffle=shuffle\n",
    "        )\n",
    "        \n",
    "        print(f\"  Queue built: {len(self.job_queue)} jobs candidates.\")\n",
    "        return self.job_queue\n",
    "\n",
    "    def run_batch(self, batch_size=batch_size, monitor_timeout_mins=monitor_timeout_mins, dry_run=False):\n",
    "        \"\"\"\n",
    "        Step 4 & 5: Submit a batch of jobs AND monitor them.\n",
    "        \"\"\"\n",
    "        if not self.job_queue:\n",
    "            print(\"Job queue is empty.\")\n",
    "            return\n",
    "\n",
    "        print(f\"[{datetime.datetime.now().time()}] Processing batch (Size: {batch_size})...\")\n",
    "        \n",
    "        pending_jobs = [j for j in self.job_queue if not j[2]]\n",
    "        if not pending_jobs:\n",
    "            print(\"  No pending jobs in queue.\")\n",
    "            return\n",
    "\n",
    "        if not os.path.exists(self.template_path):\n",
    "            print(f\"  Error: Template not found at {self.template_path}\")\n",
    "            return\n",
    "            \n",
    "        with open(self.template_path, 'r') as f:\n",
    "            template_content = f.read()\n",
    "\n",
    "        active_batch_jobs = [] # format: {'job_name': str, 'node': str, 'start_time': float, 'item_ref': list}\n",
    "        jobs_submitted_count = 0\n",
    "        \n",
    "        # --- SUBMISSION LOOP ---\n",
    "        for job_info in pending_jobs:\n",
    "            if jobs_submitted_count >= batch_size:\n",
    "                break\n",
    "                \n",
    "            node_name = job_info[0]\n",
    "            # Create Job Name\n",
    "            ts = int(time.time())\n",
    "            job_name = f\"hari-gcr-ceval-{node_name}-{ts}\"\n",
    "            \n",
    "            # YAML substitution\n",
    "            # FIX: Correctly substitute placeholders found in templates/specific-node-job.yml\n",
    "            # Previously used a hardcoded node name string which was incorrect for this template\n",
    "            job_yaml = template_content.replace(\"nodename-placeholder\", node_name)\n",
    "            job_yaml = job_yaml.replace(\"time-placeholder\", str(ts))\n",
    "            \n",
    "            # Replace job name placeholder\n",
    "            job_yaml = job_yaml.replace(\"generateName: jobname-placeholder\", f\"name: {job_name}\")\n",
    "            \n",
    "            print(f\"  > Target: {node_name} | Job: {job_name}\")\n",
    "            \n",
    "            if dry_run:\n",
    "                print(\"    [Dry Run] Job would be submitted. (Marking as done in queue)\")\n",
    "                job_info[2] = True # Mark submitted mock\n",
    "                jobs_submitted_count += 1\n",
    "                continue\n",
    "                \n",
    "            # Create Temp File & Submit\n",
    "            # Save to gitignored directory for debugging/inspection\n",
    "            temp_dir = os.path.join(home_dir, \"gitignored\")\n",
    "            os.makedirs(temp_dir, exist_ok=True)\n",
    "            temp_path = os.path.join(temp_dir, f\"{job_name}.yaml\")\n",
    "            \n",
    "            try:\n",
    "                with open(temp_path, 'w') as temp_f:\n",
    "                    temp_f.write(job_yaml)\n",
    "                out = functions.create_job(temp_path)\n",
    "                print(f\"    Submitted: {out.strip()}\")\n",
    "                \n",
    "                # Update queue info status (submitted=True)\n",
    "                job_info[2] = True\n",
    "                \n",
    "                active_batch_jobs.append({\n",
    "                    'job_name': job_name,\n",
    "                    'node': node_name,\n",
    "                    'start_time': time.time(),\n",
    "                    'item_ref': job_info # Reference to queue item to update status later if needed\n",
    "                })\n",
    "                jobs_submitted_count += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    Failed to submit: {e}\")\n",
    "            finally:\n",
    "                # Keep the file for debugging since user requested \"keep the directory\"\n",
    "                # if os.path.exists(temp_path):\n",
    "                #    os.remove(temp_path)\n",
    "                pass\n",
    "\n",
    "        if dry_run:\n",
    "            print(\"Batch dry-run complete.\")\n",
    "            return\n",
    "\n",
    "        # --- MONITORING LOOP ---\n",
    "        print(f\"  Scanning {len(active_batch_jobs)} jobs for status (Timeout: {monitor_timeout_mins}m)...\")\n",
    "        timeout_seconds = monitor_timeout_mins * 60\n",
    "        \n",
    "        while len(active_batch_jobs) > 0:\n",
    "            print(f\"  [{datetime.datetime.now().time()}] Checking specific job statuses...\")\n",
    "            \n",
    "            # Iterate backwards to remove finished jobs safely\n",
    "            for i in range(len(active_batch_jobs) - 1, -1, -1):\n",
    "                job = active_batch_jobs[i]\n",
    "                jname = job['job_name']\n",
    "                elapsed = time.time() - job['start_time']\n",
    "                \n",
    "                # Get Status\n",
    "                status = functions.get_job_status(jname, namespace=self.ns)\n",
    "                \n",
    "                print(f\"    [{jname}] Status: {status} (Elapsed: {elapsed:.0f}s)\")\n",
    "                \n",
    "                # Logic: Succeeded / Failed / Completed -> Done\n",
    "                if status in [\"Completed\", \"Succeeded\", \"Failed\", \"Aborted\", \"Terminated\"]:\n",
    "                    print(f\"    Job {jname}: {status}. Finished.\")\n",
    "                    active_batch_jobs.pop(i)\n",
    "                elif status == \"Pending\":\n",
    "                    # Check timeout\n",
    "                    if elapsed > timeout_seconds:\n",
    "                        print(f\"    Job {jname}: Timed out ({elapsed:.0f}s > {timeout_seconds}s). Cancelling...\")\n",
    "                        functions.delete_job(jname, namespace=self.ns)\n",
    "                        active_batch_jobs.pop(i)\n",
    "                else:\n",
    "                    # Running or Unknown\n",
    "                    pass\n",
    "            \n",
    "            if not active_batch_jobs:\n",
    "                break\n",
    "                \n",
    "            time.sleep(60) # Poll every minute\n",
    "            \n",
    "        print(\"Batch monitoring complete.\")\n",
    "\n",
    "    def process_full_queue(self, batch_size=batch_size, monitor_timeout_mins=monitor_timeout_mins, dry_run=False):\n",
    "        \"\"\"\n",
    "        Runs multiple batches until the queue is empty.\n",
    "        \"\"\"\n",
    "        print(f\"[{datetime.datetime.now().time()}] Starting Full Queue Processing (Dry Run: {dry_run})...\")\n",
    "        \n",
    "        while True:\n",
    "            # Check if there are any pending jobs\n",
    "            pending_jobs = [j for j in self.job_queue if not j[2]]\n",
    "            if not pending_jobs:\n",
    "                print(\"No more pending jobs in the queue. All done.\")\n",
    "                break\n",
    "                \n",
    "            print(f\"\\n--- Batch Start (Remaining: {len(pending_jobs)}) ---\")\n",
    "            self.run_batch(batch_size=batch_size, monitor_timeout_mins=monitor_timeout_mins, dry_run=dry_run)\n",
    "            \n",
    "            # Optional: Short pause between batches if not dry_run to allow cluster stabilization\n",
    "            if not dry_run and len(pending_jobs) > batch_size:\n",
    "                 time.sleep(10)\n",
    "\n",
    "    def latest_test_results(self):\n",
    "        \"\"\"Helper to print human readable status from loaded DB map\"\"\"\n",
    "        return self.db_status\n",
    "\n",
    "    def freenodes(self):\n",
    "        \"\"\"Helper to return cached list\"\"\"\n",
    "        return self.freenode_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "024f0c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:34:38.129081] Refreshing cluster state...\n",
      "  Found 63 free nodes (fully avaialble).\n",
      "  Fetching DB status from cluster...\n",
      "  Retrieved status for 107 nodes from DB.\n",
      "Free Nodes: 63\n",
      "DB Records: 107\n"
     ]
    }
   ],
   "source": [
    "cluster = Cluster(\"gcr-admin\")\n",
    "cluster.refresh_state()\n",
    "print(f\"Free Nodes: {len(cluster.freenodes())}\")\n",
    "print(f\"DB Records: {len(cluster.latest_test_results())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ceb56c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'node': 'slc01-cl02-hgx-0006', 'timestamp_num': 1768262075, 'timestamp_ca': '2026-01-12 15:54:35 PST', 'age_days': 0.74, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0008', 'timestamp_num': 1768262076, 'timestamp_ca': '2026-01-12 15:54:36 PST', 'age_days': 0.74, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0009', 'timestamp_num': 1768262076, 'timestamp_ca': '2026-01-12 15:54:36 PST', 'age_days': 0.74, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0012', 'timestamp_num': 1768262077, 'timestamp_ca': '2026-01-12 15:54:37 PST', 'age_days': 0.74, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0016', 'timestamp_num': 1768262511, 'timestamp_ca': '2026-01-12 16:01:51 PST', 'age_days': 0.73, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0017', 'timestamp_num': 1768262511, 'timestamp_ca': '2026-01-12 16:01:51 PST', 'age_days': 0.73, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0022', 'timestamp_num': 1768262512, 'timestamp_ca': '2026-01-12 16:01:52 PST', 'age_days': 0.73, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0023', 'timestamp_num': 1768262079, 'timestamp_ca': '2026-01-12 15:54:39 PST', 'age_days': 0.74, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0024', 'timestamp_num': 1768262513, 'timestamp_ca': '2026-01-12 16:01:53 PST', 'age_days': 0.73, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0027', 'timestamp_num': 1768260957, 'timestamp_ca': '2026-01-12 15:35:57 PST', 'age_days': 0.75, 'validity': 'expired'}\n",
      "{'node': 'slc01-cl02-hgx-0029', 'timestamp_num': 1768261783, 'timestamp_ca': '2026-01-12 15:49:43 PST', 'age_days': 0.74, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0031', 'timestamp_num': 1768262513, 'timestamp_ca': '2026-01-12 16:01:53 PST', 'age_days': 0.73, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0034', 'timestamp_num': 1768262055, 'timestamp_ca': '2026-01-12 15:54:15 PST', 'age_days': 0.74, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0047', 'timestamp_num': 1768262660, 'timestamp_ca': '2026-01-12 16:04:20 PST', 'age_days': 0.73, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0054', 'timestamp_num': 1768262660, 'timestamp_ca': '2026-01-12 16:04:20 PST', 'age_days': 0.73, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0057', 'timestamp_num': 1768324409, 'timestamp_ca': '2026-01-13 09:13:29 PST', 'age_days': 0.02, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0062', 'timestamp_num': 1768262661, 'timestamp_ca': '2026-01-12 16:04:21 PST', 'age_days': 0.73, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0073', 'timestamp_num': 1768262661, 'timestamp_ca': '2026-01-12 16:04:21 PST', 'age_days': 0.73, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0081', 'timestamp_num': 1768324409, 'timestamp_ca': '2026-01-13 09:13:29 PST', 'age_days': 0.02, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0082', 'timestamp_num': 1768262662, 'timestamp_ca': '2026-01-12 16:04:22 PST', 'age_days': 0.73, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0083', 'timestamp_num': 1768262932, 'timestamp_ca': '2026-01-12 16:08:52 PST', 'age_days': 0.73, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0084', 'timestamp_num': 1768268061, 'timestamp_ca': '2026-01-12 17:34:21 PST', 'age_days': 0.67, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0085', 'timestamp_num': 1768261508, 'timestamp_ca': '2026-01-12 15:45:08 PST', 'age_days': 0.74, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0099', 'timestamp_num': 1768262932, 'timestamp_ca': '2026-01-12 16:08:52 PST', 'age_days': 0.73, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0104', 'timestamp_num': 1768262932, 'timestamp_ca': '2026-01-12 16:08:52 PST', 'age_days': 0.73, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0107', 'timestamp_num': 1768261781, 'timestamp_ca': '2026-01-12 15:49:41 PST', 'age_days': 0.74, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0111', 'timestamp_num': 1768262933, 'timestamp_ca': '2026-01-12 16:08:53 PST', 'age_days': 0.73, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0112', 'timestamp_num': 1768324410, 'timestamp_ca': '2026-01-13 09:13:30 PST', 'age_days': 0.02, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0115', 'timestamp_num': 1768262933, 'timestamp_ca': '2026-01-12 16:08:53 PST', 'age_days': 0.73, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0118', 'timestamp_num': 1768263266, 'timestamp_ca': '2026-01-12 16:14:26 PST', 'age_days': 0.72, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0119', 'timestamp_num': 1768263267, 'timestamp_ca': '2026-01-12 16:14:27 PST', 'age_days': 0.72, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0124', 'timestamp_num': 1768263267, 'timestamp_ca': '2026-01-12 16:14:27 PST', 'age_days': 0.72, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0130', 'timestamp_num': 1768260415, 'timestamp_ca': '2026-01-12 15:26:55 PST', 'age_days': 0.76, 'validity': 'expired'}\n",
      "{'node': 'slc01-cl02-hgx-0143', 'timestamp_num': 1768260416, 'timestamp_ca': '2026-01-12 15:26:56 PST', 'age_days': 0.76, 'validity': 'expired'}\n",
      "{'node': 'slc01-cl02-hgx-0145', 'timestamp_num': 1768263268, 'timestamp_ca': '2026-01-12 16:14:28 PST', 'age_days': 0.72, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0148', 'timestamp_num': 1768263268, 'timestamp_ca': '2026-01-12 16:14:28 PST', 'age_days': 0.72, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0160', 'timestamp_num': 1768263539, 'timestamp_ca': '2026-01-12 16:18:59 PST', 'age_days': 0.72, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0163', 'timestamp_num': 1768263540, 'timestamp_ca': '2026-01-12 16:19:00 PST', 'age_days': 0.72, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0164', 'timestamp_num': 1768263540, 'timestamp_ca': '2026-01-12 16:19:00 PST', 'age_days': 0.72, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0165', 'timestamp_num': 1768263541, 'timestamp_ca': '2026-01-12 16:19:01 PST', 'age_days': 0.72, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0166', 'timestamp_num': 1768261234, 'timestamp_ca': '2026-01-12 15:40:34 PST', 'age_days': 0.75, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0169', 'timestamp_num': 1768263543, 'timestamp_ca': '2026-01-12 16:19:03 PST', 'age_days': 0.72, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0170', 'timestamp_num': 1768263813, 'timestamp_ca': '2026-01-12 16:23:33 PST', 'age_days': 0.72, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0179', 'timestamp_num': 1768261506, 'timestamp_ca': '2026-01-12 15:45:06 PST', 'age_days': 0.74, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0183', 'timestamp_num': 1768262054, 'timestamp_ca': '2026-01-12 15:54:14 PST', 'age_days': 0.74, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0184', 'timestamp_num': 1768261507, 'timestamp_ca': '2026-01-12 15:45:07 PST', 'age_days': 0.74, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0188', 'timestamp_num': 1768263814, 'timestamp_ca': '2026-01-12 16:23:34 PST', 'age_days': 0.72, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0190', 'timestamp_num': 1768260686, 'timestamp_ca': '2026-01-12 15:31:26 PST', 'age_days': 0.75, 'validity': 'expired'}\n",
      "{'node': 'slc01-cl02-hgx-0191', 'timestamp_num': 1768263814, 'timestamp_ca': '2026-01-12 16:23:34 PST', 'age_days': 0.72, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0192', 'timestamp_num': 1768263815, 'timestamp_ca': '2026-01-12 16:23:35 PST', 'age_days': 0.72, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0196', 'timestamp_num': 1768262055, 'timestamp_ca': '2026-01-12 15:54:15 PST', 'age_days': 0.74, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0199', 'timestamp_num': 1768260960, 'timestamp_ca': '2026-01-12 15:36:00 PST', 'age_days': 0.75, 'validity': 'expired'}\n",
      "{'node': 'slc01-cl02-hgx-0200', 'timestamp_num': 1768263815, 'timestamp_ca': '2026-01-12 16:23:35 PST', 'age_days': 0.72, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0202', 'timestamp_num': 1768264088, 'timestamp_ca': '2026-01-12 16:28:08 PST', 'age_days': 0.71, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0209', 'timestamp_num': 1768264088, 'timestamp_ca': '2026-01-12 16:28:08 PST', 'age_days': 0.71, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0220', 'timestamp_num': 1768268062, 'timestamp_ca': '2026-01-12 17:34:22 PST', 'age_days': 0.67, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0231', 'timestamp_num': 1768324411, 'timestamp_ca': '2026-01-13 09:13:31 PST', 'age_days': 0.02, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0232', 'timestamp_num': 1768264089, 'timestamp_ca': '2026-01-12 16:28:09 PST', 'age_days': 0.71, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0234', 'timestamp_num': 1768262056, 'timestamp_ca': '2026-01-12 15:54:16 PST', 'age_days': 0.74, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0237', 'timestamp_num': 1768264089, 'timestamp_ca': '2026-01-12 16:28:09 PST', 'age_days': 0.71, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0239', 'timestamp_num': 1768264090, 'timestamp_ca': '2026-01-12 16:28:10 PST', 'age_days': 0.71, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0247', 'timestamp_num': 1768261232, 'timestamp_ca': '2026-01-12 15:40:32 PST', 'age_days': 0.75, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0259', 'timestamp_num': 1768264363, 'timestamp_ca': '2026-01-12 16:32:43 PST', 'age_days': 0.71, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0263', 'timestamp_num': 1768261233, 'timestamp_ca': '2026-01-12 15:40:33 PST', 'age_days': 0.75, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0264', 'timestamp_num': 1768261782, 'timestamp_ca': '2026-01-12 15:49:42 PST', 'age_days': 0.74, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0289', 'timestamp_num': 1768260687, 'timestamp_ca': '2026-01-12 15:31:27 PST', 'age_days': 0.75, 'validity': 'expired'}\n",
      "{'node': 'slc01-cl02-hgx-0308', 'timestamp_num': 1768264364, 'timestamp_ca': '2026-01-12 16:32:44 PST', 'age_days': 0.71, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0309', 'timestamp_num': 1768260416, 'timestamp_ca': '2026-01-12 15:26:56 PST', 'age_days': 0.76, 'validity': 'expired'}\n",
      "{'node': 'slc01-cl02-hgx-0311', 'timestamp_num': 1768264365, 'timestamp_ca': '2026-01-12 16:32:45 PST', 'age_days': 0.71, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0312', 'timestamp_num': 1768264366, 'timestamp_ca': '2026-01-12 16:32:46 PST', 'age_days': 0.71, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0317', 'timestamp_num': 1768264638, 'timestamp_ca': '2026-01-12 16:37:18 PST', 'age_days': 0.71, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0318', 'timestamp_num': 1768264638, 'timestamp_ca': '2026-01-12 16:37:18 PST', 'age_days': 0.71, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0323', 'timestamp_num': 1768264639, 'timestamp_ca': '2026-01-12 16:37:19 PST', 'age_days': 0.71, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0327', 'timestamp_num': 1768260961, 'timestamp_ca': '2026-01-12 15:36:01 PST', 'age_days': 0.75, 'validity': 'expired'}\n",
      "{'node': 'slc01-cl02-hgx-0328', 'timestamp_num': 1768261509, 'timestamp_ca': '2026-01-12 15:45:09 PST', 'age_days': 0.74, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0332', 'timestamp_num': 1768264640, 'timestamp_ca': '2026-01-12 16:37:20 PST', 'age_days': 0.71, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0336', 'timestamp_num': 1768265036, 'timestamp_ca': '2026-01-12 16:43:56 PST', 'age_days': 0.7, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0354', 'timestamp_num': 1768261783, 'timestamp_ca': '2026-01-12 15:49:43 PST', 'age_days': 0.74, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0361', 'timestamp_num': 1768265037, 'timestamp_ca': '2026-01-12 16:43:57 PST', 'age_days': 0.7, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0362', 'timestamp_num': 1768265037, 'timestamp_ca': '2026-01-12 16:43:57 PST', 'age_days': 0.7, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0365', 'timestamp_num': 1768265038, 'timestamp_ca': '2026-01-12 16:43:58 PST', 'age_days': 0.7, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0371', 'timestamp_num': 1768260687, 'timestamp_ca': '2026-01-12 15:31:27 PST', 'age_days': 0.75, 'validity': 'expired'}\n",
      "{'node': 'slc01-cl02-hgx-0373', 'timestamp_num': 1768265038, 'timestamp_ca': '2026-01-12 16:43:58 PST', 'age_days': 0.7, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0378', 'timestamp_num': 1768265310, 'timestamp_ca': '2026-01-12 16:48:30 PST', 'age_days': 0.7, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0379', 'timestamp_num': 1768261508, 'timestamp_ca': '2026-01-12 15:45:08 PST', 'age_days': 0.74, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0382', 'timestamp_num': 1768324412, 'timestamp_ca': '2026-01-13 09:13:32 PST', 'age_days': 0.02, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0388', 'timestamp_num': 1768265311, 'timestamp_ca': '2026-01-12 16:48:31 PST', 'age_days': 0.7, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0391', 'timestamp_num': 1768324735, 'timestamp_ca': '2026-01-13 09:18:55 PST', 'age_days': 0.01, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0393', 'timestamp_num': 1768260417, 'timestamp_ca': '2026-01-12 15:26:57 PST', 'age_days': 0.76, 'validity': 'expired'}\n",
      "{'node': 'slc01-cl02-hgx-0395', 'timestamp_num': 1768265311, 'timestamp_ca': '2026-01-12 16:48:31 PST', 'age_days': 0.7, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0398', 'timestamp_num': 1768261781, 'timestamp_ca': '2026-01-12 15:49:41 PST', 'age_days': 0.74, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0399', 'timestamp_num': 1768260688, 'timestamp_ca': '2026-01-12 15:31:28 PST', 'age_days': 0.75, 'validity': 'expired'}\n",
      "{'node': 'slc01-cl02-hgx-0402', 'timestamp_num': 1768265312, 'timestamp_ca': '2026-01-12 16:48:32 PST', 'age_days': 0.7, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0403', 'timestamp_num': 1768260688, 'timestamp_ca': '2026-01-12 15:31:28 PST', 'age_days': 0.75, 'validity': 'expired'}\n",
      "{'node': 'slc01-cl02-hgx-0408', 'timestamp_num': 1768265312, 'timestamp_ca': '2026-01-12 16:48:32 PST', 'age_days': 0.7, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0417', 'timestamp_num': 1768265583, 'timestamp_ca': '2026-01-12 16:53:03 PST', 'age_days': 0.7, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0419', 'timestamp_num': 1768260417, 'timestamp_ca': '2026-01-12 15:26:57 PST', 'age_days': 0.76, 'validity': 'expired'}\n",
      "{'node': 'slc01-cl02-hgx-0422', 'timestamp_num': 1768265584, 'timestamp_ca': '2026-01-12 16:53:04 PST', 'age_days': 0.7, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0432', 'timestamp_num': 1768265584, 'timestamp_ca': '2026-01-12 16:53:04 PST', 'age_days': 0.7, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0433', 'timestamp_num': 1768261234, 'timestamp_ca': '2026-01-12 15:40:34 PST', 'age_days': 0.75, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0438', 'timestamp_num': 1768260959, 'timestamp_ca': '2026-01-12 15:35:59 PST', 'age_days': 0.75, 'validity': 'expired'}\n",
      "{'node': 'slc01-cl02-hgx-0440', 'timestamp_num': 1768265585, 'timestamp_ca': '2026-01-12 16:53:05 PST', 'age_days': 0.7, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0445', 'timestamp_num': 1768265585, 'timestamp_ca': '2026-01-12 16:53:05 PST', 'age_days': 0.7, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0449', 'timestamp_num': 1768262054, 'timestamp_ca': '2026-01-12 15:54:14 PST', 'age_days': 0.74, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0460', 'timestamp_num': 1768265855, 'timestamp_ca': '2026-01-12 16:57:35 PST', 'age_days': 0.69, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0472', 'timestamp_num': 1768265856, 'timestamp_ca': '2026-01-12 16:57:36 PST', 'age_days': 0.69, 'validity': 'valid'}\n",
      "{'node': 'slc01-cl02-hgx-0479', 'timestamp_num': 1768268062, 'timestamp_ca': '2026-01-12 17:34:22 PST', 'age_days': 0.67, 'validity': 'valid'}\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timezone\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "LA = ZoneInfo(\"America/Los_Angeles\")\n",
    "\n",
    "def add_age_and_validity(results: dict[str, int], validity_days: float = 2.0):\n",
    "    now_utc = datetime.now(timezone.utc)\n",
    "    out = []\n",
    "    for node, ts in results.items():\n",
    "        ts_dt_utc = datetime.fromtimestamp(int(ts), tz=timezone.utc)\n",
    "        age_days = (now_utc - ts_dt_utc).total_seconds() / 86400.0\n",
    "\n",
    "        out.append({\n",
    "            \"node\": node,\n",
    "            \"timestamp_num\": int(ts),\n",
    "            \"timestamp_ca\": ts_dt_utc.astimezone(LA).strftime(\"%Y-%m-%d %H:%M:%S %Z\"),\n",
    "            \"age_days\": round(age_days, 2),\n",
    "            \"validity\": \"valid\" if age_days <= validity_days else \"expired\",\n",
    "        })\n",
    "    return out\n",
    "\n",
    "rows = add_age_and_validity(cluster.latest_test_results(), validity_days=.75)\n",
    "for r in sorted(rows, key=lambda x: x[\"node\"]):\n",
    "    print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8c3cf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "# from zoneinfo import ZoneInfo\n",
    "\n",
    "# LA = ZoneInfo(\"America/Los_Angeles\")\n",
    "\n",
    "# def fmt_ca(epoch_s: int) -> str:\n",
    "#     return datetime.fromtimestamp(epoch_s, tz=LA).strftime(\"%Y-%m-%d %H:%M:%S %Z\")\n",
    "\n",
    "# results = cluster.latest_test_results()  # {\"node\": 1768262075, ...}\n",
    "\n",
    "# # Pretty print\n",
    "# for node, ts in sorted(results.items()):\n",
    "#     print(f\"{node}: {ts}  ->  {fmt_ca(ts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "728a8d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build Queue (e.g. nodes not tested in last 2 days)\n",
    "# # Use shuffle=True to randomize the order of jobs\n",
    "# queue = cluster.build_priority_queue(days_threshold=.71, shuffle=False)\n",
    "\n",
    "# print(\"\\n Jobs in Queue:\")\n",
    "# for item in queue:\n",
    "#     print(f\"  {item[0]} (Last Tested: {item[1]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a7f6378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:25:14.118443] Building priority queue (Threshold: 2 days, Shuffle: False)...\n",
      "Building priority queue at 2026-01-13T17:25:14.118905+00:00 with threshold 2 days\n",
      "  Skipping node slc01-cl02-hgx-0006: Age 0.73 days\n",
      "  Skipping node slc01-cl02-hgx-0008: Age 0.73 days\n",
      "  Skipping node slc01-cl02-hgx-0016: Age 0.72 days\n",
      "  Skipping node slc01-cl02-hgx-0024: Age 0.72 days\n",
      "  Skipping node slc01-cl02-hgx-0031: Age 0.72 days\n",
      "  Skipping node slc01-cl02-hgx-0034: Age 0.73 days\n",
      "  Skipping node slc01-cl02-hgx-0047: Age 0.72 days\n",
      "  Skipping node slc01-cl02-hgx-0054: Age 0.72 days\n",
      "  Skipping node slc01-cl02-hgx-0062: Age 0.72 days\n",
      "  Skipping node slc01-cl02-hgx-0073: Age 0.72 days\n",
      "  Skipping node slc01-cl02-hgx-0081: Age 0.01 days\n",
      "  Skipping node slc01-cl02-hgx-0082: Age 0.72 days\n",
      "  Skipping node slc01-cl02-hgx-0085: Age 0.74 days\n",
      "  Skipping node slc01-cl02-hgx-0099: Age 0.72 days\n",
      "  Skipping node slc01-cl02-hgx-0112: Age 0.01 days\n",
      "  Skipping node slc01-cl02-hgx-0115: Age 0.72 days\n",
      "  Skipping node slc01-cl02-hgx-0118: Age 0.72 days\n",
      "  Skipping node slc01-cl02-hgx-0119: Age 0.72 days\n",
      "  Skipping node slc01-cl02-hgx-0130: Age 0.75 days\n",
      "  Skipping node slc01-cl02-hgx-0145: Age 0.72 days\n",
      "  Skipping node slc01-cl02-hgx-0148: Age 0.72 days\n",
      "  Skipping node slc01-cl02-hgx-0163: Age 0.71 days\n",
      "  Skipping node slc01-cl02-hgx-0164: Age 0.71 days\n",
      "  Skipping node slc01-cl02-hgx-0166: Age 0.74 days\n",
      "  Skipping node slc01-cl02-hgx-0169: Age 0.71 days\n",
      "  Skipping node slc01-cl02-hgx-0170: Age 0.71 days\n",
      "  Skipping node slc01-cl02-hgx-0179: Age 0.74 days\n",
      "  Skipping node slc01-cl02-hgx-0184: Age 0.74 days\n",
      "  Skipping node slc01-cl02-hgx-0188: Age 0.71 days\n",
      "  Skipping node slc01-cl02-hgx-0190: Age 0.75 days\n",
      "  Skipping node slc01-cl02-hgx-0192: Age 0.71 days\n",
      "  Skipping node slc01-cl02-hgx-0200: Age 0.71 days\n",
      "  Skipping node slc01-cl02-hgx-0209: Age 0.71 days\n",
      "  Skipping node slc01-cl02-hgx-0231: Age 0.01 days\n",
      "  Skipping node slc01-cl02-hgx-0232: Age 0.71 days\n",
      "  Skipping node slc01-cl02-hgx-0237: Age 0.71 days\n",
      "  Skipping node slc01-cl02-hgx-0247: Age 0.74 days\n",
      "  Skipping node slc01-cl02-hgx-0259: Age 0.70 days\n",
      "  Skipping node slc01-cl02-hgx-0308: Age 0.70 days\n",
      "  Skipping node slc01-cl02-hgx-0323: Age 0.70 days\n",
      "  Skipping node slc01-cl02-hgx-0327: Age 0.74 days\n",
      "  Skipping node slc01-cl02-hgx-0328: Age 0.74 days\n",
      "  Skipping node slc01-cl02-hgx-0354: Age 0.73 days\n",
      "  Skipping node slc01-cl02-hgx-0361: Age 0.70 days\n",
      "  Skipping node slc01-cl02-hgx-0362: Age 0.70 days\n",
      "  Skipping node slc01-cl02-hgx-0365: Age 0.70 days\n",
      "  Skipping node slc01-cl02-hgx-0378: Age 0.69 days\n",
      "  Skipping node slc01-cl02-hgx-0379: Age 0.74 days\n",
      "  Skipping node slc01-cl02-hgx-0382: Age 0.01 days\n",
      "  Skipping node slc01-cl02-hgx-0391: Age 0.00 days\n",
      "  Skipping node slc01-cl02-hgx-0393: Age 0.75 days\n",
      "  Skipping node slc01-cl02-hgx-0395: Age 0.69 days\n",
      "  Skipping node slc01-cl02-hgx-0399: Age 0.75 days\n",
      "  Skipping node slc01-cl02-hgx-0402: Age 0.69 days\n",
      "  Skipping node slc01-cl02-hgx-0403: Age 0.75 days\n",
      "  Skipping node slc01-cl02-hgx-0408: Age 0.69 days\n",
      "  Skipping node slc01-cl02-hgx-0417: Age 0.69 days\n",
      "  Skipping node slc01-cl02-hgx-0419: Age 0.75 days\n",
      "  Skipping node slc01-cl02-hgx-0422: Age 0.69 days\n",
      "  Skipping node slc01-cl02-hgx-0432: Age 0.69 days\n",
      "  Skipping node slc01-cl02-hgx-0433: Age 0.74 days\n",
      "  Skipping node slc01-cl02-hgx-0445: Age 0.69 days\n",
      "  Skipping node slc01-cl02-hgx-0460: Age 0.69 days\n",
      "  Queue built: 0 jobs candidates.\n",
      "[09:25:14.119390] Starting Full Queue Processing (Dry Run: False)...\n",
      "No more pending jobs in the queue. All done.\n"
     ]
    }
   ],
   "source": [
    "# Build Queue\n",
    "queue = cluster.build_priority_queue(days_threshold=2, shuffle=False)\n",
    "\n",
    "# Process the entire queue with batches. \n",
    "# dry_run=True for tests \n",
    "cluster.process_full_queue(batch_size=5, monitor_timeout_mins=3, dry_run=False) # Set dry_run=True for testing without submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ed58b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total jobs in queue: 0\n",
      "Submitted jobs count: 0\n",
      "Pending jobs count: 0\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check queue Status\n",
    "print(f\"Total jobs in queue: {len(cluster.job_queue)}\")\n",
    "submitted = [j for j in cluster.job_queue if j[2]]\n",
    "print(f\"Submitted jobs count: {len(submitted)}\")\n",
    "pending = [j for j in cluster.job_queue if not j[2]]\n",
    "print(f\"Pending jobs count: {len(pending)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fc73c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " DAILY VALIDATION SUMMARY REPORT - 2026-01-13 09:25:14\n",
      "============================================================\n",
      "\n",
      "[1] JOB EXECUTION STATS\n",
      "  • Total Candidates Queued : 0\n",
      "  • Jobs Successfully Run   : 0\n",
      "  • Jobs Pending/Skipped    : 0\n",
      "\n",
      "[2] BUSY NODES ANALYSIS (SKIPPED)\n",
      "  • Total Busy Nodes (in DB): 44\n",
      "  • Busy & Overdue (> 7 days): 0\n",
      "\n",
      "[3] Report saved to: /home/hari/b200/validation/c-val/gitignored/reports/daily_report_20260113.txt\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# NEW CELL: Daily Summary Report\n",
    "# ==========================================\n",
    "\n",
    "def generate_daily_report(cluster_obj):\n",
    "    report_lines = []\n",
    "    \n",
    "    # Helper to print to screen and save to list\n",
    "    def log(line=\"\"):\n",
    "        print(line)\n",
    "        report_lines.append(line)\n",
    "\n",
    "    now_str = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    log(\"\\n\" + \"=\"*60)\n",
    "    log(f\" DAILY VALIDATION SUMMARY REPORT - {now_str}\")\n",
    "    log(\"=\"*60)\n",
    "\n",
    "    # --- 1. Job Execution Summary ---\n",
    "    # job_queue format: [node_name, priority, submitted_boolean]\n",
    "    total_queued = len(cluster_obj.job_queue)\n",
    "    jobs_executed = [j for j in cluster_obj.job_queue if j[2] is True]\n",
    "    count_run = len(jobs_executed)\n",
    "    count_skipped = total_queued - count_run\n",
    "\n",
    "    log(f\"\\n[1] JOB EXECUTION STATS\")\n",
    "    log(f\"  • Total Candidates Queued : {total_queued}\")\n",
    "    log(f\"  • Jobs Successfully Run   : {count_run}\")\n",
    "    log(f\"  • Jobs Pending/Skipped    : {count_skipped}\")\n",
    "\n",
    "    # --- 2. Missed Opportunities (Busy Nodes) ---\n",
    "    # Logic: Find nodes that are in the DB (known) BUT are not in the free_list (busy)\n",
    "    # Then check if they are overdue.\n",
    "    \n",
    "    # Get sets of nodes\n",
    "    all_known_nodes = set(cluster_obj.db_status.keys()) # Nodes that have history\n",
    "    free_nodes = set(cluster_obj.freenode_list)         # Nodes currently free\n",
    "    busy_nodes = all_known_nodes - free_nodes           # Busy nodes\n",
    "    \n",
    "    # Calculate overdue busy nodes\n",
    "    current_time = time.time()\n",
    "    threshold_seconds = cluster_obj.days_threshold * 86400\n",
    "    \n",
    "    overdue_busy_list = []\n",
    "    \n",
    "    for node in busy_nodes:\n",
    "        last_ts = cluster_obj.db_status.get(node, 0)\n",
    "        age_seconds = current_time - last_ts\n",
    "        age_days = age_seconds / 86400.0\n",
    "        \n",
    "        # If never tested (0) or older than threshold\n",
    "        if last_ts == 0 or age_seconds > threshold_seconds:\n",
    "            last_seen_str = datetime.datetime.fromtimestamp(last_ts).strftime('%Y-%m-%d') if last_ts > 0 else \"NEVER\"\n",
    "            overdue_busy_list.append({\n",
    "                'node': node,\n",
    "                'age': age_days,\n",
    "                'last_seen': last_seen_str\n",
    "            })\n",
    "    \n",
    "    # Sort by age (descending)\n",
    "    overdue_busy_list.sort(key=lambda x: x['age'], reverse=True)\n",
    "\n",
    "    log(f\"\\n[2] BUSY NODES ANALYSIS (SKIPPED)\")\n",
    "    log(f\"  • Total Busy Nodes (in DB): {len(busy_nodes)}\")\n",
    "    log(f\"  • Busy & Overdue (> {cluster_obj.days_threshold} days): {len(overdue_busy_list)}\")\n",
    "    \n",
    "    if overdue_busy_list:\n",
    "        log(f\"\\n  [Top 15 Overdue Busy Nodes]\")\n",
    "        log(f\"  {'Node Name':<30} | {'Last Tested':<12} | {'Age (Days)'}\")\n",
    "        log(f\"  {'-'*30} | {'-'*12} | {'-'*10}\")\n",
    "        for item in overdue_busy_list[:15]:\n",
    "            log(f\"  {item['node']:<30} | {item['last_seen']:<12} | {item['age']:.1f}\")\n",
    "\n",
    "    # --- 3. Save Report ---\n",
    "    report_dir = os.path.join(cluster_obj.home_dir, \"gitignored\", \"reports\")\n",
    "    os.makedirs(report_dir, exist_ok=True)\n",
    "    filename = f\"daily_report_{datetime.datetime.now().strftime('%Y%m%d')}.txt\"\n",
    "    file_path = os.path.join(report_dir, filename)\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, \"w\") as f:\n",
    "            f.write(\"\\n\".join(report_lines))\n",
    "        print(f\"\\n[3] Report saved to: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[!] Error saving report: {e}\")\n",
    "\n",
    "# --- EXECUTE ---\n",
    "generate_daily_report(cluster)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
