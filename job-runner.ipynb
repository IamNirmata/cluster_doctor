{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6480392e",
   "metadata": {},
   "source": [
    "home directory: cluster_doctor\n",
    "function availability : ./kubectl/functions.py\n",
    "\n",
    "Now the job-runner.ipynb will perform the following tasks:\n",
    "1. get_free_node_list()\n",
    "    - save it to list - get_free_node_list[]\n",
    "2. get_db_latest_status() \n",
    "    - Get latest test results timmestamp from validation.db for all the nodes in the db ( by accessing gcr-admin-pvc-access pod)\n",
    "    - per node per test - latest timestamp\n",
    "    - if a node has no test results - mark it with very old timestamp - highest priority\n",
    "3. build_priority_queue()\n",
    "    - Combine free nodes list with get_db_latest_status list, and create a priority queue function that takes \n",
    "        1. free nodes list\n",
    "        2. db latest status\n",
    "        3. Z days threshold\n",
    "    - Returns priority queue\n",
    "        1. Filered free nodes only\n",
    "        2. skip nodes with test results not older than Z days \n",
    "        3. order by latest test results timestamps (oldest first - highest priority) \n",
    "    - Format of returned \"job_priority_queue_list\": [ nodename, priority_order, job_submission_status ]\n",
    "        [\n",
    "            [node1, 1, True],\n",
    "            [node2, 2, False],\n",
    "            ...\n",
    "        ]\n",
    "4. batch job submission\n",
    "   - takes \n",
    "        1. batch size: N single node jobs per batch\n",
    "        2. job queue list from build_priority_queue()\n",
    "        3. job template yaml file path  ( /home/hari/b200/validation/cluster_doctor/ymls/specific-node-job.yml )\n",
    "    - for each batch of N nodes\n",
    "        1. read job template yaml file\n",
    "        2. edit/ fill in \n",
    "            a. node name <node-name>\n",
    "            b. job name hari-gcr-ceval-<node-name>-<timestamp>\n",
    "        3. submit job to k8s cluster and repeat N times ( for batch size )\n",
    "5. monitor job status\n",
    "    - if a job pending for more than X minutes - cancel the job and update job_submission_status to canceled in job_priority_queue_list\n",
    "For each node in job queue list\n",
    "    - Create a job to run cluster-doctor validation tests on that node\n",
    "\n",
    "6. Job run[Inside Job pod] \n",
    "    - git clone cluster_doctor repo to /opt/cluster_doctor\n",
    "    - Run cluster-doctor tests on the pod/node and collect logs ( STDOUT/ STDERR) using tee\n",
    "    - Upon completion of tests\n",
    "        -Collect test results log ( STDOUT/ STDERR) and save it to /data/continuous_validation/<test-name>/<node-name>/<node-name>-<testname>-<timestamp>.log\n",
    "    - Update validation.db with new test results and timestamp at /data/continuous_validation/metadata/validation.db using /opt/cluster_doctor/kubectl/functions.py/add_result_local()\n",
    "\n",
    "7. Generate a daily report\n",
    "    - Summary of nodes tested\n",
    "    - Summary of test results\n",
    "    - List of nodes that were never tested\n",
    "    - Save report to ./gitignored/reports/daily_report_<date>.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7935a907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import importlib\n",
    "\n",
    "# Add the current directory to path to ensure we can import utils\n",
    "current_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "if current_dir not in sys.path:\n",
    "    sys.path.append(current_dir)\n",
    "\n",
    "# Import the utility functions\n",
    "try:\n",
    "    import utils.functions as functions\n",
    "    importlib.reload(functions) # Force reload to get new functions\n",
    "except ImportError:\n",
    "    # Fallback if running from a different context\n",
    "    sys.path.append(\"/home/hari/b200/validation/cluster_doctor\")\n",
    "    import utils.functions as functions\n",
    "    importlib.reload(functions)\n",
    "\n",
    "home_dir = \"/home/hari/b200/validation/cluster_doctor/\"\n",
    "batch_size = 2\n",
    "monitor_timeout_mins = 2\n",
    "\n",
    "class Cluster:\n",
    "    def __init__(self, ns=\"gcr-admin\"):\n",
    "        self.ns = ns\n",
    "        # numerical timestamp\n",
    "        self.timestamp = int(time.time())\n",
    "        self.freenode_list = []\n",
    "        self.db_status = {}\n",
    "        self.job_queue = []\n",
    "        self.template_path = os.path.join(home_dir, \"ymls/specific-node-job.yml\")\n",
    "        \n",
    "    def refresh_state(self):\n",
    "        \"\"\"\n",
    "        Step 1 & 2: Get free nodes and latest DB status.\n",
    "        \"\"\"\n",
    "        print(f\"[{datetime.datetime.now().time()}] Refreshing cluster state...\")\n",
    "        \n",
    "        # 1. Get Free Node List\n",
    "        self.freenode_list = functions.get_free_node_list()\n",
    "        print(f\"  Found {len(self.freenode_list)} free nodes (fully avaialble).\")\n",
    "        \n",
    "        # 2. Get DB Latest Status\n",
    "        print(\"  Fetching DB status from cluster...\")\n",
    "        try:\n",
    "            db_output = functions.get_db_latest_status(namespace=self.ns)\n",
    "            self.db_status = functions.parse_db_status_output(db_output)\n",
    "            print(f\"  Retrieved status for {len(self.db_status)} nodes from DB.\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error fetching DB status: {e}\")\n",
    "            self.db_status = {}\n",
    "            \n",
    "    def build_priority_queue(self, days_threshold=7, shuffle=False):\n",
    "        \"\"\"\n",
    "        Step 3: Build a priority queue filtering free nodes by age of last test.\n",
    "        \"\"\"\n",
    "        if not self.freenode_list:\n",
    "            print(\"No free nodes to queue.\")\n",
    "            self.job_queue = []\n",
    "            return []\n",
    "\n",
    "        print(f\"[{datetime.datetime.now().time()}] Building priority queue (Threshold: {days_threshold} days, Shuffle: {shuffle})...\")\n",
    "        self.job_queue = functions.build_priority_queue(\n",
    "            self.freenode_list, \n",
    "            self.db_status, \n",
    "            days_threshold=days_threshold,\n",
    "            shuffle=shuffle\n",
    "        )\n",
    "        \n",
    "        print(f\"  Queue built: {len(self.job_queue)} jobs candidates.\")\n",
    "        return self.job_queue\n",
    "\n",
    "    def run_batch(self, batch_size=batch_size, monitor_timeout_mins=monitor_timeout_mins, dry_run=False):\n",
    "        \"\"\"\n",
    "        Step 4 & 5: Submit a batch of jobs AND monitor them.\n",
    "        \"\"\"\n",
    "        if not self.job_queue:\n",
    "            print(\"Job queue is empty.\")\n",
    "            return\n",
    "\n",
    "        print(f\"[{datetime.datetime.now().time()}] Processing batch (Size: {batch_size})...\")\n",
    "        \n",
    "        pending_jobs = [j for j in self.job_queue if not j[2]]\n",
    "        if not pending_jobs:\n",
    "            print(\"  No pending jobs in queue.\")\n",
    "            return\n",
    "\n",
    "        if not os.path.exists(self.template_path):\n",
    "            print(f\"  Error: Template not found at {self.template_path}\")\n",
    "            return\n",
    "            \n",
    "        with open(self.template_path, 'r') as f:\n",
    "            template_content = f.read()\n",
    "\n",
    "        active_batch_jobs = [] # format: {'job_name': str, 'node': str, 'start_time': float, 'item_ref': list}\n",
    "        jobs_submitted_count = 0\n",
    "        \n",
    "        # --- SUBMISSION LOOP ---\n",
    "        for job_info in pending_jobs:\n",
    "            if jobs_submitted_count >= batch_size:\n",
    "                break\n",
    "                \n",
    "            node_name = job_info[0]\n",
    "            # Create Job Name\n",
    "            ts = int(time.time())\n",
    "            job_name = f\"hari-gcr-ceval-{node_name}-{ts}\"\n",
    "            \n",
    "            # YAML substitution\n",
    "            # FIX: Correctly substitute placeholders found in templates/specific-node-job.yml\n",
    "            # Previously used a hardcoded node name string which was incorrect for this template\n",
    "            job_yaml = template_content.replace(\"nodename-placeholder\", node_name)\n",
    "            job_yaml = job_yaml.replace(\"time-placeholder\", str(ts))\n",
    "            \n",
    "            # Replace job name placeholder\n",
    "            job_yaml = job_yaml.replace(\"generateName: jobname-placeholder\", f\"name: {job_name}\")\n",
    "            \n",
    "            print(f\"  > Target: {node_name} | Job: {job_name}\")\n",
    "            \n",
    "            if dry_run:\n",
    "                print(\"    [Dry Run] Job would be submitted. (Marking as done in queue)\")\n",
    "                job_info[2] = True # Mark submitted mock\n",
    "                jobs_submitted_count += 1\n",
    "                continue\n",
    "                \n",
    "            # Create Temp File & Submit\n",
    "            # Save to gitignored directory for debugging/inspection\n",
    "            temp_dir = os.path.join(home_dir, \"gitignored\")\n",
    "            os.makedirs(temp_dir, exist_ok=True)\n",
    "            temp_path = os.path.join(temp_dir, f\"{job_name}.yaml\")\n",
    "            \n",
    "            try:\n",
    "                with open(temp_path, 'w') as temp_f:\n",
    "                    temp_f.write(job_yaml)\n",
    "                out = functions.create_job(temp_path)\n",
    "                print(f\"    Submitted: {out.strip()}\")\n",
    "                \n",
    "                # Update queue info status (submitted=True)\n",
    "                job_info[2] = True\n",
    "                \n",
    "                active_batch_jobs.append({\n",
    "                    'job_name': job_name,\n",
    "                    'node': node_name,\n",
    "                    'start_time': time.time(),\n",
    "                    'item_ref': job_info # Reference to queue item to update status later if needed\n",
    "                })\n",
    "                jobs_submitted_count += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    Failed to submit: {e}\")\n",
    "            finally:\n",
    "                # Keep the file for debugging since user requested \"keep the directory\"\n",
    "                # if os.path.exists(temp_path):\n",
    "                #    os.remove(temp_path)\n",
    "                pass\n",
    "\n",
    "        if dry_run:\n",
    "            print(\"Batch dry-run complete.\")\n",
    "            return\n",
    "\n",
    "        # --- MONITORING LOOP ---\n",
    "        print(f\"  Scanning {len(active_batch_jobs)} jobs for status (Timeout: {monitor_timeout_mins}m)...\")\n",
    "        timeout_seconds = monitor_timeout_mins * 60\n",
    "        \n",
    "        while len(active_batch_jobs) > 0:\n",
    "            print(f\"  [{datetime.datetime.now().time()}] Checking specific job statuses...\")\n",
    "            \n",
    "            # Iterate backwards to remove finished jobs safely\n",
    "            for i in range(len(active_batch_jobs) - 1, -1, -1):\n",
    "                job = active_batch_jobs[i]\n",
    "                jname = job['job_name']\n",
    "                elapsed = time.time() - job['start_time']\n",
    "                \n",
    "                # Get Status\n",
    "                status = functions.get_job_status(jname, namespace=self.ns)\n",
    "                \n",
    "                print(f\"    [{jname}] Status: {status} (Elapsed: {elapsed:.0f}s)\")\n",
    "                \n",
    "                # Logic: Succeeded / Failed / Completed -> Done\n",
    "                if status in [\"Completed\", \"Succeeded\", \"Failed\", \"Aborted\", \"Terminated\"]:\n",
    "                    print(f\"    Job {jname}: {status}. Finished.\")\n",
    "                    active_batch_jobs.pop(i)\n",
    "                elif status == \"Pending\":\n",
    "                    # Check timeout\n",
    "                    if elapsed > timeout_seconds:\n",
    "                        print(f\"    Job {jname}: Timed out ({elapsed:.0f}s > {timeout_seconds}s). Cancelling...\")\n",
    "                        functions.delete_job(jname, namespace=self.ns)\n",
    "                        active_batch_jobs.pop(i)\n",
    "                else:\n",
    "                    # Running or Unknown\n",
    "                    pass\n",
    "            \n",
    "            if not active_batch_jobs:\n",
    "                break\n",
    "                \n",
    "            time.sleep(60) # Poll every minute\n",
    "            \n",
    "        print(\"Batch monitoring complete.\")\n",
    "\n",
    "    def process_full_queue(self, batch_size=batch_size, monitor_timeout_mins=monitor_timeout_mins, dry_run=False):\n",
    "        \"\"\"\n",
    "        Runs multiple batches until the queue is empty.\n",
    "        \"\"\"\n",
    "        print(f\"[{datetime.datetime.now().time()}] Starting Full Queue Processing (Dry Run: {dry_run})...\")\n",
    "        \n",
    "        while True:\n",
    "            # Check if there are any pending jobs\n",
    "            pending_jobs = [j for j in self.job_queue if not j[2]]\n",
    "            if not pending_jobs:\n",
    "                print(\"No more pending jobs in the queue. All done.\")\n",
    "                break\n",
    "                \n",
    "            print(f\"\\n--- Batch Start (Remaining: {len(pending_jobs)}) ---\")\n",
    "            self.run_batch(batch_size=batch_size, monitor_timeout_mins=monitor_timeout_mins, dry_run=dry_run)\n",
    "            \n",
    "            # Optional: Short pause between batches if not dry_run to allow cluster stabilization\n",
    "            if not dry_run and len(pending_jobs) > batch_size:\n",
    "                 time.sleep(10)\n",
    "\n",
    "    def latest_test_results(self):\n",
    "        \"\"\"Helper to print human readable status from loaded DB map\"\"\"\n",
    "        return self.db_status\n",
    "\n",
    "    def freenodes(self):\n",
    "        \"\"\"Helper to return cached list\"\"\"\n",
    "        return self.freenode_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "024f0c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:32:31.444193] Refreshing cluster state...\n",
      "  Found 112 free nodes (fully avaialble).\n",
      "  Fetching DB status from cluster...\n",
      "  Retrieved status for 2 nodes from DB.\n",
      "Free Nodes: 112\n",
      "DB Records: 2\n"
     ]
    }
   ],
   "source": [
    "cluster = Cluster(\"gcr-admin\")\n",
    "cluster.refresh_state()\n",
    "print(f\"Free Nodes: {len(cluster.freenodes())}\")\n",
    "print(f\"DB Records: {len(cluster.latest_test_results())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "728a8d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:33:03.587165] Building priority queue (Threshold: 2 days, Shuffle: True)...\n",
      "  Queue built: 112 jobs candidates.\n",
      "\n",
      "Top 10 Jobs in Queue:\n",
      "  slc01-cl02-hgx-0403 (Last Tested: 1)\n",
      "  slc01-cl02-hgx-0472 (Last Tested: 2)\n",
      "  slc01-cl02-hgx-0081 (Last Tested: 3)\n",
      "  slc01-cl02-hgx-0209 (Last Tested: 4)\n",
      "  slc01-cl02-hgx-0050 (Last Tested: 5)\n",
      "  slc01-cl02-hgx-0408 (Last Tested: 6)\n",
      "  slc01-cl02-hgx-0104 (Last Tested: 7)\n",
      "  slc01-cl02-hgx-0254 (Last Tested: 8)\n",
      "  slc01-cl02-hgx-0145 (Last Tested: 9)\n",
      "  slc01-cl02-hgx-0247 (Last Tested: 10)\n"
     ]
    }
   ],
   "source": [
    "# Build Queue (e.g. nodes not tested in last 2 days)\n",
    "# Use shuffle=True to randomize the order of jobs\n",
    "queue = cluster.build_priority_queue(days_threshold=2, shuffle=True)\n",
    "\n",
    "print(\"\\nTop 10 Jobs in Queue:\")\n",
    "for item in queue[:10]:\n",
    "    print(f\"  {item[0]} (Last Tested: {item[1]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1a7f6378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:33:03.615139] Building priority queue (Threshold: 2 days, Shuffle: True)...\n",
      "  Queue built: 112 jobs candidates.\n",
      "[19:33:03.615617] Starting Full Queue Processing (Dry Run: False)...\n",
      "\n",
      "--- Batch Start (Remaining: 112) ---\n",
      "[19:33:03.615641] Processing batch (Size: 1)...\n",
      "  > Target: slc01-cl02-hgx-0023 | Job: hari-gcr-ceval-slc01-cl02-hgx-0023-1767929583\n",
      "    Submitted: job.batch.volcano.sh/hari-gcr-ceval-slc01-cl02-hgx-0023-1767929583 created\n",
      "  Scanning 1 jobs for status (Timeout: 2m)...\n",
      "  [19:33:04.167742] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0023-1767929583] Status: Pending (Elapsed: 0s)\n",
      "  [19:34:04.599379] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0023-1767929583] Status: Completed (Elapsed: 60s)\n",
      "    Job hari-gcr-ceval-slc01-cl02-hgx-0023-1767929583: Completed. Finished.\n",
      "Batch monitoring complete.\n",
      "\n",
      "--- Batch Start (Remaining: 111) ---\n",
      "[19:34:15.026187] Processing batch (Size: 1)...\n",
      "  > Target: slc01-cl02-hgx-0145 | Job: hari-gcr-ceval-slc01-cl02-hgx-0145-1767929655\n",
      "    Submitted: job.batch.volcano.sh/hari-gcr-ceval-slc01-cl02-hgx-0145-1767929655 created\n",
      "  Scanning 1 jobs for status (Timeout: 2m)...\n",
      "  [19:34:15.528184] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0145-1767929655] Status: Pending (Elapsed: 0s)\n",
      "  [19:35:16.103700] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0145-1767929655] Status: Completed (Elapsed: 61s)\n",
      "    Job hari-gcr-ceval-slc01-cl02-hgx-0145-1767929655: Completed. Finished.\n",
      "Batch monitoring complete.\n",
      "\n",
      "--- Batch Start (Remaining: 110) ---\n",
      "[19:35:26.594925] Processing batch (Size: 1)...\n",
      "  > Target: slc01-cl02-hgx-0200 | Job: hari-gcr-ceval-slc01-cl02-hgx-0200-1767929726\n",
      "    Submitted: job.batch.volcano.sh/hari-gcr-ceval-slc01-cl02-hgx-0200-1767929726 created\n",
      "  Scanning 1 jobs for status (Timeout: 2m)...\n",
      "  [19:35:27.299266] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0200-1767929726] Status: Pending (Elapsed: 0s)\n",
      "  [19:36:27.691407] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0200-1767929726] Status: Completed (Elapsed: 60s)\n",
      "    Job hari-gcr-ceval-slc01-cl02-hgx-0200-1767929726: Completed. Finished.\n",
      "Batch monitoring complete.\n",
      "\n",
      "--- Batch Start (Remaining: 109) ---\n",
      "[19:36:38.224661] Processing batch (Size: 1)...\n",
      "  > Target: slc01-cl02-hgx-0119 | Job: hari-gcr-ceval-slc01-cl02-hgx-0119-1767929798\n",
      "    Submitted: job.batch.volcano.sh/hari-gcr-ceval-slc01-cl02-hgx-0119-1767929798 created\n",
      "  Scanning 1 jobs for status (Timeout: 2m)...\n",
      "  [19:36:38.767465] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0119-1767929798] Status: Pending (Elapsed: 0s)\n",
      "  [19:37:39.246664] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0119-1767929798] Status: Completed (Elapsed: 60s)\n",
      "    Job hari-gcr-ceval-slc01-cl02-hgx-0119-1767929798: Completed. Finished.\n",
      "Batch monitoring complete.\n",
      "\n",
      "--- Batch Start (Remaining: 108) ---\n",
      "[19:37:49.631820] Processing batch (Size: 1)...\n",
      "  > Target: slc01-cl02-hgx-0371 | Job: hari-gcr-ceval-slc01-cl02-hgx-0371-1767929869\n",
      "    Submitted: job.batch.volcano.sh/hari-gcr-ceval-slc01-cl02-hgx-0371-1767929869 created\n",
      "  Scanning 1 jobs for status (Timeout: 2m)...\n",
      "  [19:37:50.154431] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0371-1767929869] Status: Pending (Elapsed: 0s)\n",
      "  [19:38:50.805093] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0371-1767929869] Status: Completed (Elapsed: 61s)\n",
      "    Job hari-gcr-ceval-slc01-cl02-hgx-0371-1767929869: Completed. Finished.\n",
      "Batch monitoring complete.\n",
      "\n",
      "--- Batch Start (Remaining: 107) ---\n",
      "[19:39:01.261116] Processing batch (Size: 1)...\n",
      "  > Target: slc01-cl02-hgx-0192 | Job: hari-gcr-ceval-slc01-cl02-hgx-0192-1767929941\n",
      "    Submitted: job.batch.volcano.sh/hari-gcr-ceval-slc01-cl02-hgx-0192-1767929941 created\n",
      "  Scanning 1 jobs for status (Timeout: 2m)...\n",
      "  [19:39:02.017594] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0192-1767929941] Status: Pending (Elapsed: 0s)\n",
      "  [19:40:02.424329] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0192-1767929941] Status: Completed (Elapsed: 60s)\n",
      "    Job hari-gcr-ceval-slc01-cl02-hgx-0192-1767929941: Completed. Finished.\n",
      "Batch monitoring complete.\n",
      "\n",
      "--- Batch Start (Remaining: 106) ---\n",
      "[19:40:12.841558] Processing batch (Size: 1)...\n",
      "  > Target: slc01-cl02-hgx-0158 | Job: hari-gcr-ceval-slc01-cl02-hgx-0158-1767930012\n",
      "    Submitted: job.batch.volcano.sh/hari-gcr-ceval-slc01-cl02-hgx-0158-1767930012 created\n",
      "  Scanning 1 jobs for status (Timeout: 2m)...\n",
      "  [19:40:13.384681] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0158-1767930012] Status: Pending (Elapsed: 0s)\n",
      "  [19:41:13.815081] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0158-1767930012] Status: Completed (Elapsed: 60s)\n",
      "    Job hari-gcr-ceval-slc01-cl02-hgx-0158-1767930012: Completed. Finished.\n",
      "Batch monitoring complete.\n",
      "\n",
      "--- Batch Start (Remaining: 105) ---\n",
      "[19:41:24.221753] Processing batch (Size: 1)...\n",
      "  > Target: slc01-cl02-hgx-0013 | Job: hari-gcr-ceval-slc01-cl02-hgx-0013-1767930084\n",
      "    Submitted: job.batch.volcano.sh/hari-gcr-ceval-slc01-cl02-hgx-0013-1767930084 created\n",
      "  Scanning 1 jobs for status (Timeout: 2m)...\n",
      "  [19:41:24.960908] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0013-1767930084] Status: Pending (Elapsed: 0s)\n",
      "  [19:42:25.488494] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0013-1767930084] Status: Completed (Elapsed: 61s)\n",
      "    Job hari-gcr-ceval-slc01-cl02-hgx-0013-1767930084: Completed. Finished.\n",
      "Batch monitoring complete.\n",
      "\n",
      "--- Batch Start (Remaining: 104) ---\n",
      "[19:42:36.044176] Processing batch (Size: 1)...\n",
      "  > Target: slc01-cl02-hgx-0354 | Job: hari-gcr-ceval-slc01-cl02-hgx-0354-1767930156\n",
      "    Submitted: job.batch.volcano.sh/hari-gcr-ceval-slc01-cl02-hgx-0354-1767930156 created\n",
      "  Scanning 1 jobs for status (Timeout: 2m)...\n",
      "  [19:42:36.544502] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0354-1767930156] Status: Pending (Elapsed: 0s)\n",
      "  [19:43:36.954059] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0354-1767930156] Status: Completed (Elapsed: 60s)\n",
      "    Job hari-gcr-ceval-slc01-cl02-hgx-0354-1767930156: Completed. Finished.\n",
      "Batch monitoring complete.\n",
      "\n",
      "--- Batch Start (Remaining: 103) ---\n",
      "[19:43:47.602544] Processing batch (Size: 1)...\n",
      "  > Target: slc01-cl02-hgx-0292 | Job: hari-gcr-ceval-slc01-cl02-hgx-0292-1767930227\n",
      "    Submitted: job.batch.volcano.sh/hari-gcr-ceval-slc01-cl02-hgx-0292-1767930227 created\n",
      "  Scanning 1 jobs for status (Timeout: 2m)...\n",
      "  [19:43:48.253392] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0292-1767930227] Status: Pending (Elapsed: 0s)\n",
      "  [19:44:48.700779] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0292-1767930227] Status: Pending (Elapsed: 60s)\n",
      "  [19:45:49.345598] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0292-1767930227] Status: Completed (Elapsed: 121s)\n",
      "    Job hari-gcr-ceval-slc01-cl02-hgx-0292-1767930227: Completed. Finished.\n",
      "Batch monitoring complete.\n",
      "\n",
      "--- Batch Start (Remaining: 102) ---\n",
      "[19:45:59.772107] Processing batch (Size: 1)...\n",
      "  > Target: slc01-cl02-hgx-0323 | Job: hari-gcr-ceval-slc01-cl02-hgx-0323-1767930359\n",
      "    Submitted: job.batch.volcano.sh/hari-gcr-ceval-slc01-cl02-hgx-0323-1767930359 created\n",
      "  Scanning 1 jobs for status (Timeout: 2m)...\n",
      "  [19:46:00.693709] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0323-1767930359] Status: Pending (Elapsed: 0s)\n",
      "  [19:47:01.179804] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0323-1767930359] Status: Completed (Elapsed: 60s)\n",
      "    Job hari-gcr-ceval-slc01-cl02-hgx-0323-1767930359: Completed. Finished.\n",
      "Batch monitoring complete.\n",
      "\n",
      "--- Batch Start (Remaining: 101) ---\n",
      "[19:47:11.621484] Processing batch (Size: 1)...\n",
      "  > Target: slc01-cl02-hgx-0083 | Job: hari-gcr-ceval-slc01-cl02-hgx-0083-1767930431\n",
      "    Submitted: job.batch.volcano.sh/hari-gcr-ceval-slc01-cl02-hgx-0083-1767930431 created\n",
      "  Scanning 1 jobs for status (Timeout: 2m)...\n",
      "  [19:47:12.225890] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0083-1767930431] Status: Pending (Elapsed: 0s)\n",
      "  [19:48:12.632098] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0083-1767930431] Status: Completed (Elapsed: 60s)\n",
      "    Job hari-gcr-ceval-slc01-cl02-hgx-0083-1767930431: Completed. Finished.\n",
      "Batch monitoring complete.\n",
      "\n",
      "--- Batch Start (Remaining: 100) ---\n",
      "[19:48:23.223522] Processing batch (Size: 1)...\n",
      "  > Target: slc01-cl02-hgx-0012 | Job: hari-gcr-ceval-slc01-cl02-hgx-0012-1767930503\n",
      "    Submitted: job.batch.volcano.sh/hari-gcr-ceval-slc01-cl02-hgx-0012-1767930503 created\n",
      "  Scanning 1 jobs for status (Timeout: 2m)...\n",
      "  [19:48:23.879804] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0012-1767930503] Status: Pending (Elapsed: 0s)\n",
      "  [19:49:24.521850] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0012-1767930503] Status: Completed (Elapsed: 61s)\n",
      "    Job hari-gcr-ceval-slc01-cl02-hgx-0012-1767930503: Completed. Finished.\n",
      "Batch monitoring complete.\n",
      "\n",
      "--- Batch Start (Remaining: 99) ---\n",
      "[19:49:35.018931] Processing batch (Size: 1)...\n",
      "  > Target: slc01-cl02-hgx-0422 | Job: hari-gcr-ceval-slc01-cl02-hgx-0422-1767930575\n",
      "    Submitted: job.batch.volcano.sh/hari-gcr-ceval-slc01-cl02-hgx-0422-1767930575 created\n",
      "  Scanning 1 jobs for status (Timeout: 2m)...\n",
      "  [19:49:35.577029] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0422-1767930575] Status: Pending (Elapsed: 0s)\n",
      "  [19:50:36.000012] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0422-1767930575] Status: Completed (Elapsed: 60s)\n",
      "    Job hari-gcr-ceval-slc01-cl02-hgx-0422-1767930575: Completed. Finished.\n",
      "Batch monitoring complete.\n",
      "\n",
      "--- Batch Start (Remaining: 98) ---\n",
      "[19:50:46.635609] Processing batch (Size: 1)...\n",
      "  > Target: slc01-cl02-hgx-0388 | Job: hari-gcr-ceval-slc01-cl02-hgx-0388-1767930646\n",
      "    Submitted: job.batch.volcano.sh/hari-gcr-ceval-slc01-cl02-hgx-0388-1767930646 created\n",
      "  Scanning 1 jobs for status (Timeout: 2m)...\n",
      "  [19:50:47.324034] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0388-1767930646] Status: Pending (Elapsed: 0s)\n",
      "  [19:51:47.862779] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0388-1767930646] Status: Completed (Elapsed: 61s)\n",
      "    Job hari-gcr-ceval-slc01-cl02-hgx-0388-1767930646: Completed. Finished.\n",
      "Batch monitoring complete.\n",
      "\n",
      "--- Batch Start (Remaining: 97) ---\n",
      "[19:51:58.462433] Processing batch (Size: 1)...\n",
      "  > Target: slc01-cl02-hgx-0164 | Job: hari-gcr-ceval-slc01-cl02-hgx-0164-1767930718\n",
      "    Submitted: job.batch.volcano.sh/hari-gcr-ceval-slc01-cl02-hgx-0164-1767930718 created\n",
      "  Scanning 1 jobs for status (Timeout: 2m)...\n",
      "  [19:51:59.244059] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0164-1767930718] Status: Pending (Elapsed: 0s)\n",
      "  [19:52:59.664276] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0164-1767930718] Status: Completed (Elapsed: 60s)\n",
      "    Job hari-gcr-ceval-slc01-cl02-hgx-0164-1767930718: Completed. Finished.\n",
      "Batch monitoring complete.\n",
      "\n",
      "--- Batch Start (Remaining: 96) ---\n",
      "[19:53:10.168596] Processing batch (Size: 1)...\n",
      "  > Target: slc01-cl02-hgx-0016 | Job: hari-gcr-ceval-slc01-cl02-hgx-0016-1767930790\n",
      "    Submitted: job.batch.volcano.sh/hari-gcr-ceval-slc01-cl02-hgx-0016-1767930790 created\n",
      "  Scanning 1 jobs for status (Timeout: 2m)...\n",
      "  [19:53:10.768734] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0016-1767930790] Status: Pending (Elapsed: 0s)\n",
      "  [19:54:11.232792] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0016-1767930790] Status: Completed (Elapsed: 60s)\n",
      "    Job hari-gcr-ceval-slc01-cl02-hgx-0016-1767930790: Completed. Finished.\n",
      "Batch monitoring complete.\n",
      "\n",
      "--- Batch Start (Remaining: 95) ---\n",
      "[19:54:21.613041] Processing batch (Size: 1)...\n",
      "  > Target: slc01-cl02-hgx-0468 | Job: hari-gcr-ceval-slc01-cl02-hgx-0468-1767930861\n",
      "    Submitted: job.batch.volcano.sh/hari-gcr-ceval-slc01-cl02-hgx-0468-1767930861 created\n",
      "  Scanning 1 jobs for status (Timeout: 2m)...\n",
      "  [19:54:22.179954] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0468-1767930861] Status: Pending (Elapsed: 0s)\n",
      "  [19:55:22.595439] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0468-1767930861] Status: Completed (Elapsed: 60s)\n",
      "    Job hari-gcr-ceval-slc01-cl02-hgx-0468-1767930861: Completed. Finished.\n",
      "Batch monitoring complete.\n",
      "\n",
      "--- Batch Start (Remaining: 94) ---\n",
      "[19:55:32.980345] Processing batch (Size: 1)...\n",
      "  > Target: slc01-cl02-hgx-0031 | Job: hari-gcr-ceval-slc01-cl02-hgx-0031-1767930932\n",
      "    Submitted: job.batch.volcano.sh/hari-gcr-ceval-slc01-cl02-hgx-0031-1767930932 created\n",
      "  Scanning 1 jobs for status (Timeout: 2m)...\n",
      "  [19:55:33.671838] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0031-1767930932] Status: Pending (Elapsed: 0s)\n",
      "  [19:56:34.093590] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0031-1767930932] Status: Completed (Elapsed: 60s)\n",
      "    Job hari-gcr-ceval-slc01-cl02-hgx-0031-1767930932: Completed. Finished.\n",
      "Batch monitoring complete.\n",
      "\n",
      "--- Batch Start (Remaining: 93) ---\n",
      "[19:56:44.536638] Processing batch (Size: 1)...\n",
      "  > Target: slc01-cl02-hgx-0399 | Job: hari-gcr-ceval-slc01-cl02-hgx-0399-1767931004\n",
      "    Submitted: job.batch.volcano.sh/hari-gcr-ceval-slc01-cl02-hgx-0399-1767931004 created\n",
      "  Scanning 1 jobs for status (Timeout: 2m)...\n",
      "  [19:56:45.426833] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0399-1767931004] Status: Pending (Elapsed: 0s)\n",
      "  [19:57:45.980364] Checking specific job statuses...\n",
      "    [hari-gcr-ceval-slc01-cl02-hgx-0399-1767931004] Status: Completed (Elapsed: 61s)\n",
      "    Job hari-gcr-ceval-slc01-cl02-hgx-0399-1767931004: Completed. Finished.\n",
      "Batch monitoring complete.\n",
      "\n",
      "--- Batch Start (Remaining: 92) ---\n",
      "[19:57:56.479423] Processing batch (Size: 1)...\n",
      "  > Target: slc01-cl02-hgx-0433 | Job: hari-gcr-ceval-slc01-cl02-hgx-0433-1767931076\n",
      "    Submitted: job.batch.volcano.sh/hari-gcr-ceval-slc01-cl02-hgx-0433-1767931076 created\n",
      "  Scanning 1 jobs for status (Timeout: 2m)...\n",
      "  [19:57:57.140645] Checking specific job statuses...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      3\u001b[39m queue = cluster.build_priority_queue(days_threshold=\u001b[32m2\u001b[39m, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Process the entire queue with batches. \u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# It will run until all nodes in the priority queue have been tested.\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Set dry_run=False to actually submit jobs.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mcluster\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess_full_queue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor_timeout_mins\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdry_run\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Set dry_run=True for testing without submission\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 216\u001b[39m, in \u001b[36mCluster.process_full_queue\u001b[39m\u001b[34m(self, batch_size, monitor_timeout_mins, dry_run)\u001b[39m\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Batch Start (Remaining: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(pending_jobs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor_timeout_mins\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmonitor_timeout_mins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdry_run\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdry_run\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[38;5;66;03m# Optional: Short pause between batches if not dry_run to allow cluster stabilization\u001b[39;00m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dry_run \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pending_jobs) > batch_size:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 177\u001b[39m, in \u001b[36mCluster.run_batch\u001b[39m\u001b[34m(self, batch_size, monitor_timeout_mins, dry_run)\u001b[39m\n\u001b[32m    174\u001b[39m elapsed = time.time() - job[\u001b[33m'\u001b[39m\u001b[33mstart_time\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    176\u001b[39m \u001b[38;5;66;03m# Get Status\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m status = \u001b[43mfunctions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_job_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m    [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] Status: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (Elapsed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.0f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    181\u001b[39m \u001b[38;5;66;03m# Logic: Succeeded / Failed / Completed -> Done\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/b200/validation/cluster_doctor/utils/functions.py:270\u001b[39m, in \u001b[36mget_job_status\u001b[39m\u001b[34m(job_name, namespace)\u001b[39m\n\u001b[32m    261\u001b[39m     \u001b[38;5;66;03m# LOGIC:\u001b[39;00m\n\u001b[32m    262\u001b[39m     \u001b[38;5;66;03m# 1. If last_ts is 0 (Never tested) -> High Priority\u001b[39;00m\n\u001b[32m    263\u001b[39m     \u001b[38;5;66;03m# 2. If age > threshold -> Add to queue\u001b[39;00m\n\u001b[32m    264\u001b[39m     \u001b[38;5;66;03m# 3. Else -> Skip (Tested recently)\u001b[39;00m\n\u001b[32m    266\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m last_ts == \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m age > threshold_seconds:\n\u001b[32m    267\u001b[39m         candidate_list.append({\n\u001b[32m    268\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mnode\u001b[39m\u001b[33m'\u001b[39m: node,\n\u001b[32m    269\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mts\u001b[39m\u001b[33m'\u001b[39m: last_ts\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m         })\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[32m    273\u001b[39m     \u001b[38;5;66;03m# RANDOMIZE: Use random shuffle\u001b[39;00m\n\u001b[32m    274\u001b[39m     random.shuffle(candidate_list)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/b200/validation/cluster_doctor/utils/functions.py:23\u001b[39m, in \u001b[36mrun_command\u001b[39m\u001b[34m(command, shell, check)\u001b[39m\n\u001b[32m     21\u001b[39m         result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=\u001b[38;5;28;01mTrue\u001b[39;00m, check=check)\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m         result = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result.stdout.decode(\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m).strip()\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess.CalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/subprocess.py:556\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    554\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Popen(*popenargs, **kwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    555\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m556\u001b[39m         stdout, stderr = \u001b[43mprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    557\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    558\u001b[39m         process.kill()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/subprocess.py:1222\u001b[39m, in \u001b[36mPopen.communicate\u001b[39m\u001b[34m(self, input, timeout)\u001b[39m\n\u001b[32m   1219\u001b[39m     endtime = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1221\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1222\u001b[39m     stdout, stderr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1224\u001b[39m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[32m   1225\u001b[39m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[32m   1226\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/subprocess.py:2128\u001b[39m, in \u001b[36mPopen._communicate\u001b[39m\u001b[34m(self, input, endtime, orig_timeout)\u001b[39m\n\u001b[32m   2121\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_timeout(endtime, orig_timeout,\n\u001b[32m   2122\u001b[39m                         stdout, stderr,\n\u001b[32m   2123\u001b[39m                         skip_check_and_raise=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   2124\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(  \u001b[38;5;66;03m# Impossible :)\u001b[39;00m\n\u001b[32m   2125\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   2126\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mfailed to raise TimeoutExpired.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2128\u001b[39m ready = \u001b[43mselector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2129\u001b[39m \u001b[38;5;28mself\u001b[39m._check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[32m   2131\u001b[39m \u001b[38;5;66;03m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[32m   2132\u001b[39m \u001b[38;5;66;03m# objects; they are no longer using C stdio!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/selectors.py:398\u001b[39m, in \u001b[36m_PollLikeSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    396\u001b[39m ready = []\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m     fd_event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# IMPORTANT: Rebuild queue before running if you want to start fresh or change shuffle mode.\n",
    "# If you ran a dry_run previously, the queue might be marked as \"processed\".\n",
    "queue = cluster.build_priority_queue(days_threshold=2, shuffle=True)\n",
    "\n",
    "# Process the entire queue with batches. \n",
    "# It will run until all nodes in the priority queue have been tested.\n",
    "# Set dry_run=False to actually submit jobs.\n",
    "cluster.process_full_queue(batch_size=1, monitor_timeout_mins=2, dry_run=False) # Set dry_run=True for testing without submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed58b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total jobs in queue: 106\n",
      "Submitted jobs count: 106\n",
      "Pending jobs count: 0\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check queue Status\n",
    "print(f\"Total jobs in queue: {len(cluster.job_queue)}\")\n",
    "submitted = [j for j in cluster.job_queue if j[2]]\n",
    "print(f\"Submitted jobs count: {len(submitted)}\")\n",
    "pending = [j for j in cluster.job_queue if not j[2]]\n",
    "print(f\"Pending jobs count: {len(pending)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
